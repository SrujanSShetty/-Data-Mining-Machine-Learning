{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the dataset\n",
    "df = pd.read_csv('C:/Users/nayak/Downloads/malware_BinaryImbalanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>os</th>\n",
       "      <th>usage_counter</th>\n",
       "      <th>prio</th>\n",
       "      <th>static_prio</th>\n",
       "      <th>normal_prio</th>\n",
       "      <th>vm_pgoff</th>\n",
       "      <th>vm_truncate_count</th>\n",
       "      <th>task_size</th>\n",
       "      <th>map_count</th>\n",
       "      <th>hiwater_rss</th>\n",
       "      <th>total_vm</th>\n",
       "      <th>shared_vm</th>\n",
       "      <th>exec_vm</th>\n",
       "      <th>reserved_vm</th>\n",
       "      <th>nr_ptes</th>\n",
       "      <th>nvcsw</th>\n",
       "      <th>nivcsw</th>\n",
       "      <th>signal_nvcsw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benign</td>\n",
       "      <td>Ubuntu</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benign</td>\n",
       "      <td>CentOS</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benign</td>\n",
       "      <td>Ubuntu</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benign</td>\n",
       "      <td>CentOS</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benign</td>\n",
       "      <td>Mac</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification      os  usage_counter        prio  static_prio  normal_prio  \\\n",
       "0         benign  Ubuntu              0  3069403136        16447            0   \n",
       "1         benign  CentOS              0  3069403136        16447            0   \n",
       "2         benign  Ubuntu              0  3069403136        16447            0   \n",
       "3         benign  CentOS              0  3069403136        16447            0   \n",
       "4         benign     Mac              0  3069403136        16447            0   \n",
       "\n",
       "   vm_pgoff  vm_truncate_count  task_size  map_count  hiwater_rss  total_vm  \\\n",
       "0         0              14739          0       7903            0        88   \n",
       "1         0              14739          0       7903            0        88   \n",
       "2         0              14739          0       7903            0        88   \n",
       "3         0              14739          0       7903            0        88   \n",
       "4         0              14739          0       7903            0        88   \n",
       "\n",
       "   shared_vm  exec_vm  reserved_vm  nr_ptes   nvcsw  nivcsw  signal_nvcsw  \n",
       "0        120      120           80        0  349169       0             0  \n",
       "1        120      120           80        0  349169       0             0  \n",
       "2        120      120           80        0  349169       0             0  \n",
       "3        120      120           80        0  349169       0             0  \n",
       "4        120      120           80        0  349169       0             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting columns specified in readme file\n",
    "df = df.loc[:, ['classification', 'os', 'usage_counter', 'prio', 'static_prio', 'normal_prio', 'vm_pgoff', 'vm_truncate_count', 'task_size', 'map_count', 'hiwater_rss', 'total_vm', 'shared_vm', 'exec_vm', 'reserved_vm', 'nr_ptes', 'nvcsw', 'nivcsw', 'signal_nvcsw']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification       0\n",
       "os                   0\n",
       "usage_counter        0\n",
       "prio                 0\n",
       "static_prio          0\n",
       "normal_prio          0\n",
       "vm_pgoff             0\n",
       "vm_truncate_count    0\n",
       "task_size            0\n",
       "map_count            0\n",
       "hiwater_rss          0\n",
       "total_vm             0\n",
       "shared_vm            0\n",
       "exec_vm              0\n",
       "reserved_vm          0\n",
       "nr_ptes              0\n",
       "nvcsw                0\n",
       "nivcsw               0\n",
       "signal_nvcsw         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the data has null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['classification'] # define label as nominal values\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y_encoded = le.transform(y) # encode nominal labels to integers\n",
    "df['classification'] = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num=df.copy(deep=True) \n",
    "# create new binary columns\n",
    "df_dummies=pd.get_dummies(df_num['os'])\n",
    "df_dummies = df_dummies.astype(int)\n",
    "# add them to dataframe\n",
    "df_num=df_num.join(df_dummies)\n",
    "# drop original columns\n",
    "df_num.drop('os', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>usage_counter</th>\n",
       "      <th>prio</th>\n",
       "      <th>static_prio</th>\n",
       "      <th>normal_prio</th>\n",
       "      <th>vm_pgoff</th>\n",
       "      <th>vm_truncate_count</th>\n",
       "      <th>task_size</th>\n",
       "      <th>map_count</th>\n",
       "      <th>hiwater_rss</th>\n",
       "      <th>...</th>\n",
       "      <th>reserved_vm</th>\n",
       "      <th>nr_ptes</th>\n",
       "      <th>nvcsw</th>\n",
       "      <th>nivcsw</th>\n",
       "      <th>signal_nvcsw</th>\n",
       "      <th>CentOS</th>\n",
       "      <th>Debian</th>\n",
       "      <th>Mac</th>\n",
       "      <th>Ubuntu</th>\n",
       "      <th>Windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3069403136</td>\n",
       "      <td>16447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14739</td>\n",
       "      <td>0</td>\n",
       "      <td>7903</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>349169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification  usage_counter        prio  static_prio  normal_prio  \\\n",
       "0               0              0  3069403136        16447            0   \n",
       "1               0              0  3069403136        16447            0   \n",
       "2               0              0  3069403136        16447            0   \n",
       "3               0              0  3069403136        16447            0   \n",
       "4               0              0  3069403136        16447            0   \n",
       "\n",
       "   vm_pgoff  vm_truncate_count  task_size  map_count  hiwater_rss  ...  \\\n",
       "0         0              14739          0       7903            0  ...   \n",
       "1         0              14739          0       7903            0  ...   \n",
       "2         0              14739          0       7903            0  ...   \n",
       "3         0              14739          0       7903            0  ...   \n",
       "4         0              14739          0       7903            0  ...   \n",
       "\n",
       "   reserved_vm  nr_ptes   nvcsw  nivcsw  signal_nvcsw  CentOS  Debian  Mac  \\\n",
       "0           80        0  349169       0             0       0       0    0   \n",
       "1           80        0  349169       0             0       1       0    0   \n",
       "2           80        0  349169       0             0       0       0    0   \n",
       "3           80        0  349169       0             0       1       0    0   \n",
       "4           80        0  349169       0             0       0       0    1   \n",
       "\n",
       "   Ubuntu  Windows  \n",
       "0       1        0  \n",
       "1       0        0  \n",
       "2       1        0  \n",
       "3       0        0  \n",
       "4       0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting n dummy variables to n-1 dummy variables\n",
    "df_num.drop('CentOS', axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification\n",
       "0    89899\n",
       "1    10101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[21846   568]\n",
      " [ 1960   626]]\n",
      "Logistic Regression By hold-out evaluation: accuracy =  0.89888 , precison =  0.7209779610196378 , recall =  0.6083656973037305\n",
      "Area under Curve =  0.9017054685810872 , f1 score =  0.6382609969801661\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - Considering the data.\n",
    "from sklearn import metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score, roc_auc_score, recall_score, f1_score, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "x = df_num.drop('classification', axis = 1)\n",
    "y = df['classification']\n",
    "\n",
    "# Logistic Regression by Hold - Out Evaluation\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25) # splitting with 75% train and 25% test\n",
    "\n",
    "clf=LogisticRegression(penalty='l2',solver='newton-cg', max_iter=150, multi_class='ovr')\n",
    "clf=clf.fit(x_train, y_train)\n",
    "y_pred=clf.predict(x_test)\n",
    "\n",
    "conf_Matrix = cm(y_test, y_pred)\n",
    "print('Confusion Matrix\\n', conf_Matrix)\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision=precision_score(y_test, y_pred, average='macro')\n",
    "recall=recall_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Logistic Regression By hold-out evaluation: accuracy = ',accuracy, ', precison = ', precision, ', recall = ', recall)\n",
    "print('Area under Curve = ',auc_value, ', f1 score = ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By N-fold Cross Validation: accuracy =  0.8495099999999999 , precision =  0.7557763606778903\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression by N-Fold Cross Validation\n",
    "clf=LogisticRegression(penalty='l2',solver='lbfgs')\n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "accuracy = cross_val_score(clf, x, y, cv=5, scoring='accuracy').mean()\n",
    "precision = cross_val_score(clf, x, y, cv=5, scoring=precision).mean()\n",
    "print('By N-fold Cross Validation: accuracy = ',accuracy, ', precision = ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine accuracy by hold-out evaluation:  0.8992\n",
      "Logistic Regression By hold-out evaluation: accuracy =  0.8992 , precison =  0.8495099999999999 , recall =  0.89828\n",
      "Area under Curve =  0.6796002619612496 , f1 score =  0.8992\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine - Hold Out Evaluation\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "clf = SVC(kernel='poly', C=0.1, max_iter=-1, probability=True) \n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Support Vector Machine accuracy by hold-out evaluation: ',accuracy)\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Logistic Regression By hold-out evaluation: accuracy = ',accuracy, ', precison = ', precision, ', recall = ', recall)\n",
    "print('Area under Curve = ',auc_value, ', f1 score = ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Random Forest by hold-out evaluation: accuracy =  0.96528 , precision =  0.9676789680665413 , area under the curve =  0.986084613266666 , f1 score 0.889246274658092\n"
     ]
    }
   ],
   "source": [
    "# Bagging - Random Forest - Hold Out Evaluation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "x = df_num.drop('classification', axis = 1)\n",
    "y = df['classification']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "bag = BaggingClassifier(tree, n_estimators=10, max_samples=0.750, random_state=1, bootstrap=False)\n",
    "clf = bag.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Bagging Random Forest by hold-out evaluation: accuracy = ',accuracy, ', precision = ', precision, ', area under the curve = ', auc_value, ', f1 score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Accuracy by N-fold Cross Validation: accuracy =  0.8449199999999999 precision =  0.5519127196131544\n"
     ]
    }
   ],
   "source": [
    "# Bagging - Random Forest - Cross Validation\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "bag = BaggingClassifier(tree, n_estimators=10, max_samples=0.75, random_state=1)\n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "accuracy = cross_val_score(bag, x, y, cv=5, scoring='accuracy').mean()\n",
    "precision = cross_val_score(bag, x, y, cv=5, scoring=precision).mean()\n",
    "print(\"RandomForest Accuracy by N-fold Cross Validation: accuracy = \",accuracy, \"precision = \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Naive Bayes by hold-out evaluation: accuracy =  0.9522 , precision =  0.883021005178763 , area under the curve =  0.9737689699204959 , f1 score 0.8570316894966999\n"
     ]
    }
   ],
   "source": [
    "# Bagging using Gaussian Naive Bayes - Hold Out Evaluation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "clf = GaussianNB()\n",
    "bag = BaggingClassifier(tree, n_estimators=10, max_samples=0.750, random_state=1, bootstrap=False)\n",
    "clf = bag.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Bagging Naive Bayes by hold-out evaluation: accuracy = ',accuracy, ', precision = ', precision, ', area under the curve = ', auc_value, ', f1 score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging using GaussianNB Accuracy by N-fold Cross Validation: accuracy =  0.7659100000000001 precision =  0.652326322875741\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "bag = BaggingClassifier(clf, n_estimators=10, max_samples=0.75, random_state=1)\n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "accuracy = cross_val_score(bag, x, y, cv=5, scoring='accuracy').mean()\n",
    "precision = cross_val_score(bag, x, y, cv=5, scoring=precision).mean()\n",
    "print(\"Bagging using GaussianNB Accuracy by N-fold Cross Validation: accuracy = \",accuracy, \"precision = \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Classifier hold-out evaluation: accuracy =  0.99696 , precision =  0.9972378203626321 , area under the curve =  0.9990133145722211 , f1 score 0.9916032853180314\n"
     ]
    }
   ],
   "source": [
    "# Boosting Algorithms - AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "clf1 = AdaBoostClassifier(tree, n_estimators=5, random_state=0)\n",
    "clf1.fit(x_train, y_train)\n",
    "y_pred = clf1.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf1.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Ada Boost Classifier hold-out evaluation: accuracy = ',accuracy, ', precision = ', precision, ', area under the curve = ', auc_value, ', f1 score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting Accuracy by N-fold Cross Validation: acc =  0.8740599999999998 precision =  0.785697537153039\n"
     ]
    }
   ],
   "source": [
    "# Ada Boosting using Cross Validation\n",
    "tree = DecisionTreeClassifier()\n",
    "clf = AdaBoostClassifier(tree, n_estimators=100, random_state=0)\n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "accuracy = cross_val_score(clf, x, y, cv=5, scoring='accuracy').mean()\n",
    "precision = cross_val_score(clf, x, y, cv=5, scoring=precision).mean()\n",
    "print(\"AdaBoosting Accuracy by N-fold Cross Validation: acc = \",accuracy, \"precision = \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting by hold-out evaluation: accuracy =  0.89804 , precision =  0.44902 , area under the curve =  0.9844048935199955 , f1 score 0.4731407135782175\n"
     ]
    }
   ],
   "source": [
    "# Boosting Algorithms - Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=0, learning_rate=0.001, criterion='squared_error')\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Gradient boosting by hold-out evaluation: accuracy = ',accuracy, ', precision = ', precision, ', area under the curve = ', auc_value, ', f1 score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting Accuracy by N-fold Cross Validation: acc =  0.8989900000000001 precision =  0.44949500000000003\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting using Cross Validation\n",
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=0, learning_rate=0.001, criterion='squared_error') \n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "accuracy=cross_val_score(clf, x, y, cv=5, scoring='accuracy').mean()\n",
    "precision=cross_val_score(clf, x, y, cv=5, scoring=precision).mean()\n",
    "print(\"AdaBoosting Accuracy by N-fold Cross Validation: acc = \",accuracy, \"precision = \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost by hold-out evaluation: accuracy =  0.99996 , precision =  0.9998012718600954 , area under the curve =  0.9999999911582318 , f1 score 0.9998894974089773\n"
     ]
    }
   ],
   "source": [
    "# XG Boost with Hold-Out Evaluation\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "clf = XGBClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('XG Boost by hold-out evaluation: accuracy = ',accuracy, ', precision = ', precision, ', area under the curve = ', auc_value, ', f1 score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boosting Accuracy by N-fold Cross Validation: accuracy =  0.86911 precision =  0.7415457497980626\n"
     ]
    }
   ],
   "source": [
    "# XG Boost with Cross Validation cv = 5\n",
    "clf = XGBClassifier()\n",
    "precision = make_scorer(precision_score, average='macro')\n",
    "accuracy = cross_val_score(clf, x, y, cv=5, scoring='accuracy').mean()\n",
    "precision = cross_val_score(clf, x, y, cv=5, scoring=precision).mean()\n",
    "print(\"XG Boosting Accuracy by N-fold Cross Validation: accuracy = \",accuracy, \"precision = \", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n",
      "0    89899\n",
      "1    10101\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# First, check the distribution of labels\n",
    "print(df_num.groupby(['classification']).size())# - data is imbalanced as it has more rows with classsification 0 than 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original dataset shape Counter({0: 89899, 1: 10101})\n",
      "After oversampling dataset shape Counter({0: 89899, 1: 89899})\n",
      "\n",
      "Original dataset shape Counter({0: 89899, 1: 10101})\n",
      "After undersampling dataset shape Counter({0: 10101, 1: 10101})\n",
      "\n",
      "Original dataset shape Counter({0: 89899, 1: 10101})\n",
      "After oversampling by SMOTE dataset shape Counter({0: 89899, 1: 89899})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "x = df_num.drop('classification',axis=1)\n",
    "y = df_num['classification']\n",
    "\n",
    "ros = RandomOverSampler(random_state=10)\n",
    "ros.fit(x, y)\n",
    "print('\\nOriginal dataset shape {}'.format(Counter(y)))\n",
    "x_resampled, y_resampled = ros.fit_resample(x, y)\n",
    "print('After oversampling dataset shape {}'.format(Counter(y_resampled)))\n",
    "\n",
    "print('\\nOriginal dataset shape {}'.format(Counter(y)))\n",
    "ros = RandomUnderSampler(random_state=30)\n",
    "ros.fit(x, y)\n",
    "x_resampled, y_resampled = ros.fit_resample(x, y)\n",
    "print('After undersampling dataset shape {}'.format(Counter(y_resampled)))\n",
    "\n",
    "ros = SMOTE(k_neighbors=2)\n",
    "ros.fit(x, y)\n",
    "print('\\nOriginal dataset shape {}'.format(Counter(y)))\n",
    "x_resampled, y_resampled = ros.fit_resample(x, y)\n",
    "print('After oversampling by SMOTE dataset shape {}'.format(Counter(y_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>usage_counter</th>\n",
       "      <th>prio</th>\n",
       "      <th>static_prio</th>\n",
       "      <th>normal_prio</th>\n",
       "      <th>vm_pgoff</th>\n",
       "      <th>vm_truncate_count</th>\n",
       "      <th>task_size</th>\n",
       "      <th>map_count</th>\n",
       "      <th>hiwater_rss</th>\n",
       "      <th>total_vm</th>\n",
       "      <th>shared_vm</th>\n",
       "      <th>exec_vm</th>\n",
       "      <th>reserved_vm</th>\n",
       "      <th>nr_ptes</th>\n",
       "      <th>nvcsw</th>\n",
       "      <th>nivcsw</th>\n",
       "      <th>signal_nvcsw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.069706e+09</td>\n",
       "      <td>18183.900070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15312.739510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8771.13948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.491120</td>\n",
       "      <td>117.920240</td>\n",
       "      <td>127.678150</td>\n",
       "      <td>205.324850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348313.071600</td>\n",
       "      <td>32.991160</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.301343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.963061e+05</td>\n",
       "      <td>4609.792765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3256.475008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3785.30516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>311.996779</td>\n",
       "      <td>3.116892</td>\n",
       "      <td>22.277995</td>\n",
       "      <td>112.717875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9117.720632</td>\n",
       "      <td>52.730176</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.069190e+09</td>\n",
       "      <td>13988.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9695.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2588.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337688.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.069446e+09</td>\n",
       "      <td>14352.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12648.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6428.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341974.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.069698e+09</td>\n",
       "      <td>16159.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15245.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7865.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347244.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.069957e+09</td>\n",
       "      <td>22182.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17663.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10684.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351667.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.070222e+09</td>\n",
       "      <td>31855.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27157.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28184.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2810.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384520.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       classification  usage_counter          prio    static_prio  \\\n",
       "count   100000.000000       100000.0  1.000000e+05  100000.000000   \n",
       "mean         0.101010            0.0  3.069706e+09   18183.900070   \n",
       "std          0.301343            0.0  2.963061e+05    4609.792765   \n",
       "min          0.000000            0.0  3.069190e+09   13988.000000   \n",
       "25%          0.000000            0.0  3.069446e+09   14352.000000   \n",
       "50%          0.000000            0.0  3.069698e+09   16159.000000   \n",
       "75%          0.000000            0.0  3.069957e+09   22182.000000   \n",
       "max          1.000000            0.0  3.070222e+09   31855.000000   \n",
       "\n",
       "       normal_prio  vm_pgoff  vm_truncate_count  task_size     map_count  \\\n",
       "count     100000.0  100000.0      100000.000000   100000.0  100000.00000   \n",
       "mean           0.0       0.0       15312.739510        0.0    8771.13948   \n",
       "std            0.0       0.0        3256.475008        0.0    3785.30516   \n",
       "min            0.0       0.0        9695.000000        0.0    2588.00000   \n",
       "25%            0.0       0.0       12648.000000        0.0    6428.00000   \n",
       "50%            0.0       0.0       15245.000000        0.0    7865.00000   \n",
       "75%            0.0       0.0       17663.000000        0.0   10684.00000   \n",
       "max            0.0       0.0       27157.000000        0.0   28184.00000   \n",
       "\n",
       "       hiwater_rss       total_vm      shared_vm        exec_vm  \\\n",
       "count     100000.0  100000.000000  100000.000000  100000.000000   \n",
       "mean           0.0     266.491120     117.920240     127.678150   \n",
       "std            0.0     311.996779       3.116892      22.277995   \n",
       "min            0.0       4.000000     112.000000      92.000000   \n",
       "25%            0.0      99.000000     114.000000     112.000000   \n",
       "50%            0.0     177.000000     120.000000     127.000000   \n",
       "75%            0.0     327.000000     120.000000     138.000000   \n",
       "max            0.0    2810.000000     120.000000     196.000000   \n",
       "\n",
       "         reserved_vm   nr_ptes          nvcsw         nivcsw  signal_nvcsw  \n",
       "count  100000.000000  100000.0  100000.000000  100000.000000      100000.0  \n",
       "mean      205.324850       0.0  348313.071600      32.991160           0.0  \n",
       "std       112.717875       0.0    9117.720632      52.730176           0.0  \n",
       "min        29.000000       0.0  337688.000000       0.000000           0.0  \n",
       "25%       112.000000       0.0  341974.000000       1.000000           0.0  \n",
       "50%       193.000000       0.0  347244.000000       9.000000           0.0  \n",
       "75%       273.000000       0.0  351667.000000      46.000000           0.0  \n",
       "max       755.000000       0.0  384520.000000     365.000000           0.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking values with zero for all rows\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with all zero values\n",
    "df_num.drop(['usage_counter', 'normal_prio', 'vm_pgoff', 'task_size', 'hiwater_rss', 'nr_ptes', 'signal_nvcsw'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN: [    0     2     3 ... 99997 99998 99999] TEST: [    1    13    23 ... 99972 99985 99994]\n",
      "\n",
      "TRAIN: [    0     1     2 ... 99996 99997 99999] TEST: [   12    14    22 ... 99986 99995 99998]\n",
      "\n",
      "TRAIN: [    0     1     2 ... 99997 99998 99999] TEST: [    7     8    16 ... 99987 99991 99992]\n",
      "\n",
      "TRAIN: [    0     1     5 ... 99995 99996 99998] TEST: [    2     3     4 ... 99989 99997 99999]\n",
      "\n",
      "TRAIN: [    1     2     3 ... 99997 99998 99999] TEST: [    0     5     9 ... 99990 99993 99996]\n",
      "\n",
      "Original dataset shape Counter({0: 71970, 1: 8030})\n",
      "After oversampling dataset shape Counter({0: 71970, 1: 71970})\n",
      "\n",
      "Original dataset shape Counter({0: 71925, 1: 8075})\n",
      "After oversampling dataset shape Counter({0: 71925, 1: 71925})\n",
      "\n",
      "Original dataset shape Counter({0: 71887, 1: 8113})\n",
      "After oversampling dataset shape Counter({0: 71887, 1: 71887})\n",
      "\n",
      "Original dataset shape Counter({0: 71896, 1: 8104})\n",
      "After oversampling dataset shape Counter({0: 71896, 1: 71896})\n",
      "\n",
      "Original dataset shape Counter({0: 71918, 1: 8082})\n",
      "After oversampling dataset shape Counter({0: 71918, 1: 71918})\n",
      "k =  5 Accuracy on 5-folds:  0.9999400000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df_knn = df_num.copy(deep=True)\n",
    "# normalize featureS\n",
    "for col in df_knn.columns:\n",
    "    if col != 'classification':# removing classification as it is label\n",
    "        df_knn[col]=(df_knn[col]-df_knn[col].min())/(df_knn[col].max()-df_knn[col].min())\n",
    "        \n",
    "X = df_knn.loc[:, df_knn.columns!='classification']\n",
    "y = df_knn.loc[:,'classification']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "data_5folds = []\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    print(\"\\nTRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    fold = [x_train, x_test, y_train, y_test]\n",
    "    data_5folds.append(fold)\n",
    "\n",
    "for k in range(5, 6, 2): \n",
    "    acc_5folds = []\n",
    "    for x_train, x_test, y_train, y_test in data_5folds:\n",
    "        print('\\nOriginal dataset shape {}'.format(Counter(y_train)))\n",
    "        ros = RandomOverSampler(random_state=10)\n",
    "        ros.fit(x_train, y_train)\n",
    "        x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
    "        print('After oversampling dataset shape {}'.format(Counter(y_resampled)))\n",
    "        clf=neighbors.KNeighborsClassifier(k, weights='uniform')\n",
    "        clf.fit(x_resampled, y_resampled)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        acc_5folds.append(acc)\n",
    "    print('k = ',k,'Accuracy on 5-folds: ', np.mean(acc_5folds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original dataset shape Counter({0: 67394, 1: 7606})\n",
      "After oversampling dataset shape Counter({0: 67394, 1: 67394})\n",
      "Bagging Random Forest by hold-out evaluation: accuracy =  0.97 , precision =  0.884738305157203 , area under the curve =  0.9956672821314703 , f1 score 0.9260842261373272\n"
     ]
    }
   ],
   "source": [
    "# Decision tree bagging after oversampling. \n",
    "\n",
    "# Over sampling the train set.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "ros = RandomOverSampler(random_state=10)\n",
    "ros.fit(x_train, y_train)\n",
    "print('\\nOriginal dataset shape {}'.format(Counter(y_train)))\n",
    "x_resampled, y_resampled = ros.fit_resample(x_train, y_train)\n",
    "print('After oversampling dataset shape {}'.format(Counter(y_resampled)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5) # max depth increased to 5 from 3\n",
    "bag = BaggingClassifier(tree, n_estimators=10, max_samples=0.750, random_state=1, bootstrap=False)\n",
    "clf = bag.fit(x_resampled, y_resampled) #using the resampled data to train\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Bagging Random Forest by hold-out evaluation: accuracy = ',accuracy, ', precision = ', precision, ', area under the curve = ', auc_value, ', f1 score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost by hold-out evaluation: accuracy =  0.99996 , precision =  0.9999777837021239 , area under the curve =  0.9999997506677429 , f1 score 0.9998886711192074\n"
     ]
    }
   ],
   "source": [
    "# using XG Boost with resampled data.\n",
    "clf = XGBClassifier()\n",
    "clf.fit(x_resampled, y_resampled)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('XG Boost by hold-out evaluation: accuracy = ',accuracy, ', precision = ', precision, ', area under the curve = ', auc_value, ', f1 score', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[17411  5094]\n",
      " [   90  2405]]\n",
      "Logistic Regression By hold-out evaluation: accuracy =  0.79264 , precison =  0.6577834323208125 , recall =  0.8687890778223855\n",
      "Area under Curve =  0.8971396158235155 , f1 score =  0.6758541051741979\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with resampled train data\n",
    "\n",
    "clf=LogisticRegression(penalty='l2',solver='newton-cg', max_iter=150, multi_class='ovr')\n",
    "clf=clf.fit(x_resampled, y_resampled)\n",
    "y_pred=clf.predict(x_test)\n",
    "\n",
    "conf_Matrix = cm(y_test, y_pred)\n",
    "print('Confusion Matrix\\n', conf_Matrix)\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision=precision_score(y_test, y_pred, average='macro')\n",
    "recall=recall_score(y_test, y_pred, average='macro')\n",
    "y_pred_proba = clf.predict_proba(x_test)\n",
    "auc_value = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print('Logistic Regression By hold-out evaluation: accuracy = ',accuracy, ', precison = ', precision, ', recall = ', recall)\n",
    "print('Area under Curve = ',auc_value, ', f1 score = ', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
